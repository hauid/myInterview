# 1.高并发问题的通用设计方法



“高并发”是后端领域的技术圣杯，是一种**可遇而不可求的特殊业务需求。**

对于每一名后端工程师来说，实现高并发的系统都是一项颇具挑战性的任务。为了应对这一挑战，你需要对**网络、缓存、并发、并行、分布式计算以及数据库优化等技术**有深入的理解和**实际经验**。在这个领域，没有虚假的掩饰，只有真实的实力。

# 概述

我们都知道，互联网服务的核心价值在于流量，流量越大，平台的盈利机会和发展空间就越大，这也是为何大厂总是倾向于招聘拥有高并发经验的研发人员。2007 年，中国电子商务总和交易额突破一万亿人民币，网民数量快速增加，中国互联网正式进入了高并发时代。之后，大厂与创业公司之间的技术壁垒不断加强。如今，掌握高并发技术已成为大厂技术人员的基本要求。

当然，**大厂可以为我们提供高并发系统架构设计的实践机会。然而，如果你没有相关的架构设计经验，大厂的大门又怎会向你敞开呢？这就形成了一个逻辑悖论。**

难道我们只能一直陷在这个困境中吗？实际上，我们自己也是这些**高并发应用的用户，例如使用微信、使用搜索引擎、刷微博、刷短视频。我们只需要将自己从用户角色转换为设计者的角色，想象自己成为这些大厂的架构师**，设身处地思考：如果我来设计这个系统，我该怎么做。()

尽管我们都知道高并发的重要性，并学习了许多高并发系统设计的技术资料，但仍然会感到困惑：为什么我们仍然缺乏对设计一个完整的高并发系统的了解？

这是因为你缺乏真实业务场景中的架构设计经验。**没有亲自接触过真实的业务需求，就无法感受到面对压力、迎接挑战以及完成任务后的喜悦和轻松。**只有通过真实的现场感受，我们学到的各种技术才能真正融会贯通，而不只是一堆零碎知识的杂乱集合。就像那句著名的“我听过很多道理，却仍然过不好这一生”。归根结底，还是缺乏实践。

通过阅读本书，你可以“化身”为那个真的需要解决高并发问题的人，**借助笔者的真实高并发处理经验**，身临其境地站在架构师的角度，深入理解高并发系统设计的哲学原理。

### 找出单点，进行拆分

开门见山，先说结论，高并发的哲学原理就是——找出单点，进行拆分。要将每一个**“大单点”**都拆成**“一个小单点 + 多个资源并行”**的形式。

### “单点”的定义

单点指的是一个 Web 系统中，**几乎所有流量都必须经过的特定部分**，如果它出现瓶颈或故障，将导致整个系统的性能下降或不可用。单点是一个逻辑概念，在系统架构层面它可能指代各种不同层面的软件、硬件实体。在传统的单体式应用中，可以说遍地都是**单点**。

在解决高并发问题的过程中，我们会不断地遇到各种单点：**Web Server、单个操作系统、虚拟化/容器技术、编程语言运行架构、网络、Unix 进程模型、数据库等**。每遇到一个单点，我们都要见招拆招，使用架构工具拆掉它。计算机的**虚拟化程度**非常高，理论上每个单点都是可以继续往下拆分的。



# 设定目标：每秒一百万次 HTTPS 请求

本书的主题既然是高并发原理与实战，那就要先设定一个高并发的目标：**每秒一百万次 HTTPS 请求**，即 1,000,000 QPS（Queries Per Second）。某些场景中，也称为：1,000,000 TPS（Transactions Per Second）。

### 性能问题要靠架构解决

在正式展开之前，我们需要明确高并发问题的基本解决思路：系统的性能问题需要通过架构设计来解决。

面对高并发技术需求时，在架构上进行优化是最为简单、对系统稳定性影响最低且最容易获得收益的方法。

即便在我们专注于单个资源的性能优化时，例如 MySQL 单机性能优化（软件优化）或 x86 CPU 多核性能提升（硬件优化），从微观角度来看，这些优化措施实际上也是在进行架构优化——通过调整软件或硬件的运行架构，提升总体性能。**(不同层次之间的共性)**

### 没有银弹

“没有银弹”是计算机世界的第一准则，你想获得性能收益，就一定要拿出一些东西，和“信息之神”交换。

架构优化的本质就是**拿其它资源或者指标来交换性能，系统总体性能的提升必然需要伴随着某种资源的更多消耗或者某个非关键指标的劣化**，像我们常说的“时间换空间”“空间换时间”都是这个道理的实际体现。

### 我们讨论哪个高并发？

本文讨论的是“Web 服务高并发”问题，典型场景为电商秒杀：同一个时刻，数万人抢同一个低价商品，会给系统的每一个层面都造成显著的性能瓶颈，每年的双 11 大促就是这一场景的极致体现。

接下来，请大家跟着笔者一起，沿着**`计算高并发` -> `网络高并发` -> `数据库（存储）高并发`**的道路一步一步将系统性能的上限从单机 100 QPS 提升到 1,000,000（一百万）QPS。





# 动态、静态资源分开部署



动静分离是高并发架构设计的第一步，部分场景下还是收益最大的那一步，因为我们可以把 99% 的流量压力都转移出去。

### Apache 和 Nginx 的性能差距

十年前，笔者用 4200 元从同学那里买到了一台二手的 Macbook Pro。彼时，Macbook Pro 还是满身接口的厚家伙，也没有细腻的视网膜屏幕，CPU 是 i5 双核，内存只有 4GB，但就是在那台电脑上，笔者使用一张静态图片测试了 Apache 和 Nginx 的性能差距：两万对八万，Nginx 的性能是 Apache 的四倍。

### 加一个 Nginx 软件竟然还能减少 CPU 和内存占用？

如果你的应用现在还在用 Apache 承载全部流量，那只需要在前面加一个 Nginx，承载静态资源的分发，动态请求可以原封不动地使用 http 协议发送给 Apache，只需要这样一个小操作，便可以在服务器配置不变的情况下把系统容量提升一倍以上。此时的系统架构图如图 1-1 所示。

此外，由于 Nginx 针对新图片格式（如 .webp）和视频流式传输等进行了专门的优化，在增加了一个软件后，服务器的 CPU 和内存资源消耗反而会明显下降。在如今流量越来越便宜的时代，静态资源的体积和流量呈指数级增长，Nginx 的性能优势还在持续扩大。

![img](https://pphc.lvwenhan.com/media/16888225935467.jpg)

图 1-1 Nginx 承载静态资源分发

### 使用云服务

如果你在用云服务的话，那么把静态资源全部交给云服务商的 CDN 来承载，还可以再获得 90% 的 CPU 节省。同时，CDN 的流量费还比云主机的流量费更便宜，时至今日中国 CDN 市场已经卷的不像样子了。此时的系统架构图如图 1-2 所示。

![2893789274893278941](https://pphc.lvwenhan.com/media/2893789274893278941.png)

图 1-2 静态资源全部使用云服务商的 CDN 服务





# 数据库独立部署



在使用 Nginx 承载全部静态资源以后，如果你的低配云主机还是扛不住流量，该怎么办呢？这个时候就需要引入第二台云主机了：专门用来跑数据库。

### 将后端代码和数据库部署在同一台机器上是“灾难架构”

出于节省成本的需要，把后端代码和数据库部署在同一台机器上确实是一个无奈的选择。但是，我们要清楚的是，这是一种错误的架构设计方案，它只适合超低流量的系统。

一旦系统承受的压力稍大，便会面临“债股双杀”的局面：

1. CPU 被耗尽导致 MySQL 响应变慢；
2. 应用代码需更长时间等待，虽不额外消耗 CPU 资源，却占用大量内存；
3. 系统内存被占用导致 InnoDB 缓存被系统回收，进一步降低了 MySQL 的运行速度；
4. 最终形成“内卷”和“踩踏”，系统性能急剧下降，服务可能完全崩溃。

### MySQL 单独部署时性能非常出色

只要你将 MySQL 与后端代码的 CPU 进行隔离，数据库的极限性能就能达到够用的水平。根据笔者的实测结果，即使是一台1 核 2G 的 MySQL 服务器，也能够达到 200QPS（Query Per Second，每秒执行的 SQL 语句数） 的每秒执行 SQL 语句数，足以支撑一个每天一百万 PV 的小网站。

### MySQL 单独部署架构图

应用服务器和 MySQL 数据库服务器分为两台机器部署时，系统架构图如图 1-3 所示。

![img](https://pphc.lvwenhan.com/media/16888306629372.jpg)

图 1-3 MySQL 单独部署架构图

### 运维哲学初探

在这个小小的例子中，我们已经在不经意间窥探到了过去数十年运维技术圈的基本哲学：从物理机到虚拟机，从虚拟主机到云主机，再从云主机到 Kubernetes，虽然推动运维架构演进的是越来越复杂的软件架构和越来越多的计算资源需求，但是运维的基本哲学是不变的：

> 运维的核心价值不在于资源的扩充，而在于资源的隔离。

我们将在后面关于云服务和服务器硬件发展的讨论中进一步探讨这一运维哲学。

