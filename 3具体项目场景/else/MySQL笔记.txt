

关系型数据库: 建立在关系模型基础上，由多张相互连接的二维表组成的数据库。
二维表的优点：
- 使用表存储数据，格式统一，便于维护
- 使用SQL语言操作，标准统一，使用方便，可用于复杂查询
mysql -u用户名 -p密码 [-h数据库服务器的IP地址 -P端口号]
- -h  参数不加，默认连接的是本地 127.0.0.1 的MySQL服务器
- -P  参数不加，默认连接的端口号是 3306
在Mysql数据库服务器当中存储数据，你需要：
1. 先去创建数据库（可以创建多个数据库，之间是相互独立的）
2. 在数据库下再去创建数据表（一个数据库下可以创建多张表）
3. 再将数据存放在数据表中（一张表可以存储多行数据）

**SQL（Structured Query Language，简称SQL）**

**结构化查询语言，它是操作关系型数据库的编程语言，定义了一套操作关系型数据库的统一标准。**
DDL Data Definition Language 		数据定义语言，用来定义数据库对象(数据库，表，字段)
DML Data Manipulation Language 	数据操作语言，用来对数据库表中的数据进行增删改
DQL Data Query Language 			数据查询语言，用来查询数据库中表的记录
DCL Data Control Language 		数据控制语言，用来创建数据库用户,控制数据库的访问权限

DDL英文全称是Data Definition Language(数据定义语言)，用来定义数据库对象(数据库、表)。

DDL中数据库的常见操作：创建、使用、删除,查询。
库操作:
- 查询所有数据库
show databases;
- 查询当前数据库
select database();
我们要操作某一个数据库，必须要切换到对应的数据库中。 
通过指令：select  database() ，就可以查询到当前所处的数据库
- 创建数据库
create database [ if not exists ] 数据库名  [default charset utf8mb4];
- 使用数据库
use 数据库名 ;
- 删除数据库
drop database [ if exists ] 数据库名 ;

表操作:
 创建
create table  表名(
        字段1  字段1类型 [约束]  [comment  字段1注释 ],
        字段2  字段2类型 [约束]  [comment  字段2注释 ],
        ......
        字段n  字段n类型 [约束]  [comment  字段n注释 ] 
) [ comment  表注释 ] ;
主键自增效果
• 定义主键的时候指定关键字 auto_increment

 约束
- 概念：**所谓约束就是作用在表中字段上的规则，用于限制存储在表中的数据。**
- 作用：就是来保证数据库当中数据的正确性、有效性和完整性。（后面的学习会验证这些）
非空约束 限制该字段的数据不能为null 								NOT NULL
唯一约束 保证该字段的所有数据都是唯一、不重复的 					UNIQUE
主键约束(非空+唯一) 主键是一行数据的唯一标识，要求非空且唯一		PRIMARY KEY
默认约束 保存数据时,如果未指定该字段的值,则采用默认值 				DEFAULT
检查约束(8.0.16版本之后) 保证字段值满足某一个条件 					CHECK
外键约束	用来让两张表的数据之间建立连接，保证数据的一致性和完整性	FOREIGN KEY


数据类型见class.java.Mysql.docx
注意事项:
double eg:
四位数, 最多出现一位小数
   score double(4,1)
char 与 varchar 都可以描述字符串，char是定长字符串，指定长度多长，就占用多少个字符，和字段值的长度无关 。而varchar是变长字符串，指定的长度为最大占用长度 。相对来说，char的性能会更高些。 一般,如果一个字段的长度是固定的，建议使用char；如：身份证号、手机号
如果一个字段的长度不是固定的,建议使用varchar；如：用户名、姓名	
eg:
    用户名 username ---长度不定, 最长不会超过50
    username varchar(50)
    手机号 phone ---固定长度为11
    phone char(11)

DDL-表结构-查询、修改、删除
how tables; 												-- 查询当前数据库的所有表
desc 表名; 												-- 查询表结构
show create table 表名; 									-- 查询建表语句
alter table 表名 add 字段名 类型(长度) [comment 注释] [约束]; 		-- 添加字段
alter table 表名 modify 字段名 新数据类型(长度); 				-- 修改字段类型
alter table 表名 change 旧字段名 新字段名 类型(长度) [comment 注释] [约束]; 
														-- 修改字段名与字段类型
alter table 表名 drop column 字段名; 							-- 删除字段
alter table 表名 rename to 新表名; 							-- 修改表名
drop table [if exists] 表名; 									-- 删除表

DML英文全称是Data Manipulation Language(数据操作语言)，用来对数据库中表的数据记录进行增、删、改操作。

➢ 添加数据（INSERT）  
insert into 表名 values (值1, 值2, ...);
-- 批量添加数据（指定字段）
insert into 表名 (字段名1, 字段名2) values (值1, 值2), (值1, 值2);
-- 批量添加数据（全部字段）
insert into 表名 values (值1, 值2, ...), (值1, 值2, ...);
insert操作的注意事项：
字符串和日期型数据应该包含在引号中。

➢ 修改数据（UPDATE）
update 表名 set 字段名1 = 值1 ,字段名2 = 值2 , .... [where 条件] ;
注意事项:
1. 修改语句的条件可以有,也可以没有,如果没有条件，则会修改整张表的所有数据。
2. 在修改数据时，一般需要同时修改公共字段update_time，将其修改为当前操作时间。

➢ 删除数据（DELETE)
delete from 表名  [where  条件] ;
注意事项:
- DELETE 语句的条件可以有，也可以没有，如果没有条件，则会删除整张表的所有数据。
- DELETE 语句不能删除某一个字段的值(可以使用UPDATE，将该字段值置为NULL即可)。
- 当进行删除全部数据操作时，会提示询问是否确认删除所有数据，直接点击Execute即可。

DQL语句
DQL英文全称是Data Query Language(数据查询语言)，用来查询数据库表中的记录。
查询关键字：SELECT
SELECT
        字段列表
FROM
        表名列表
WHERE
        条件列表
GROUP  BY
        分组字段列表
HAVING
        分组后条件列表
ORDER BY
        排序字段列表
LIMIT
        分页参数
⚫ 基本查询（select...from...）
- 查询多个字段
  select 字段1, 字段2, 字段3 from  表名;
- 查询所有字段（通配符）
  select *  from  表名;
- 设置别名
  select 字段1 [ as 别名1 ] , 字段2 [ as 别名2 ]  from  表名;
- 去除重复记录(eg:查询已有的员工关联了哪几种职位(不要重复))
  select distinct 字段列表 from  表名;    





⚫ 条件查询（where）
select  字段列表  from   表名   where   条件列表 ; -- 条件列表：意味着可以有多个条件

> 						大于
>= 						大于等于
< 						小于
<= 						小于等于
= 						等于
<> 或 != 					不等于
between ... and ... 			在某个范围之内(含最小、最大值)
in(...) 					在in之后的列表中的值,多选一
like 						占位符 模糊匹配(_匹配单个字符, %匹配任意个字符)
is null 					是null

and 或 && 				并且 (多个条件同时成立)
or 或 || 					或者 (多个条件任意一个成立)
not 或 !					非 , 不是
⚫ 分组查询（group by）
分组其实就是按列进行分类(指定列下相同的数据归为一类)，然后可以对分类完的数据进行合并计算,分组查询通常会使用聚合函数进行计算。
注意 : 聚合函数会忽略空值，对NULL值不作为统计。
- count ：按照列去统计有多少行数据。
  select count(*) from emp;		 //count(*)  推荐此写法（MySQL底层进行了优化）
  - 在根据指定的列统计的时候，如果这一列中有null的行，该行不会被统计在其中。
- sum ：计算指定列的数值和，如果不是数值类型，那么计算结果为0
- max ：计算指定列的最大值
- min ：计算指定列的最小值
- avg ：计算指定列的平均值
语法:
select  字段列表  from  表名  [where 条件]  group by 分组字段名  [having 分组后过滤条件];

注意事项:
- 分组之后，查询的字段一般为聚合函数和分组字段，查询其他字段无任何意义
- 执行顺序：where > group by>聚合函数 > having 

where与having区别（面试题）
- 执行时机不同：where是分组之前进行过滤，不满足where条件，不参与分组；而having是分组之后对结果进行过滤。
- 判断条件不同：where不能对聚合函数进行判断，而having可以。
⚫ 排序查询（order by）
select  字段列表  
from   表名   
[where  条件列表] 
[group by  分组字段 ] 
order  by  字段1  排序方式1 , 字段2  排序方式2 … ;
- 排序方式： ASC ：升序（默认值） DESC：降序 
注意事项：如果是多字段排序，当第一个字段值相同时，才会根据第二个字段进行排序 
⚫ 分页查询（limit）
select  字段列表  from  表名  limit  起始索引, 查询记录数 ;
注意事项:
1. 起始索引从0开始。        计算公式 ：起始索引 = (查询页码 - 1)* 每页显示记录数
2. 分页查询是数据库的方言,MySQL中是LIMIT
3. 如果查询的是第一页数据，起始索引可以省略，直接简写为 limit条数

各个表结构之间也存在着各种联系，基本上分为三种:一对多(多对一),多对多, 一对一
一对多(多对一):
实现:在数据库表中多的一方，添加字段,来关联一的一方的主键即外键约束或使用逻辑约束
alter table emp  add  constraint  fk_dept_id  foreign key (dept_id)  references  dept(id);
或者在左侧菜单栏，在emp表上右键，选择 modify Table... (old UI)

一对一
一对一关系表在实际开发中应用起来比较简单，通常是用来做单表的拆分
实现:在任意一方加入外键，关联另外一方的主键，并且设置外键为唯一的(UNIQUE)

多对多
实现：建立第三张中间表，中间表至少包含两个外键，分别关联两方主键


多表查询
只需要使用逗号分隔多张表即可，如： select   字段列表  from  表1, 表2;
笛卡尔积：笛卡尔乘积是指在数学中，两个集合(A集合和B集合)的所有组合情况。
去除无效的笛卡尔积: 只需要给多表查询加上连接查询的条件即可

多表查询分类
1. 连接查询
- 内连接：相当于查询A、B交集部分数据
隐式内连接:
select  字段列表   from   表1 , 表2   where  条件 ... ;
显式内连接:
select  字段列表   from   表1  [ inner ]  	 join 表2  on  连接条件 .. where  条件 ... ;
在多表联查时，我们指定字段时，需要在字段名前面加上表名，来指定具体是哪一张的字段。 如：emp.dept_id
表起别名:
select  字段列表 from 表1 别名1 , 表2  别名2  where  条件 ... ;  -- as 可以省略

- 外连接
    - 左外连接：查询左表所有数据(包括两张表交集部分数据)
    - 右外连接：查询右表所有数据(包括两张表交集部分数据)
    左外连接语法：
    select  字段列表   from   表1  left  [ outer ]  join 表2  on  连接条件 ... where  条件 .. ;
    右外连接语法：
    select  字段列表   from   表1  right  [ outer ]  join 表2  on  连接条件 ... where  条件 .. ;

2. 子查询
SQL语句中嵌套select语句，称为嵌套查询，又称子查询。
根据子查询结果的不同分为：
1. 标量子查询（子查询结果为单个值 [一行一列]）
2. 列子查询（子查询结果为一列，但可以是多行）
3. 行子查询（子查询结果为一行，但可以是多列）
4. 表子查询（子查询结果为多行多列[相当于子查询结果是一张表]):常作为临时表,进行多表查询



















事务的四大特性主要是：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）
MySQL事务隔离备注:
脏读:a第一次读,b进行一次修改还没提交,a再读一次发现数据已经变了,这时就是脏读.
不可重复读:a第一次读,然后事务b进行一次修改并且提交,a再读一次发现数据已经变了,这时就是不可重复读取.(按照事务的性质即使b提交了,a也不应该读到变了的数据,因为此时a事务没执行完)
幻读:a第一次读发现不存在,然后b进行一次添加并且提交,a然后进行添加时发现已经存在,无法添加,但进行查找的时候还是显示不存在.(Serializable 解决这个问题就是控制事务只能串行执行,b压根就添加不了数据,必须等事务a完成)

Read uncommitted:脏读,不可重复读,幻读
Read committed:不可重复读,幻读
Repeatable Read(默认):幻读 
Serializable:无





HashMap和Hashtable的区别
1.底层数据结构不同:jdk1.7底层都是数组+链表,但jdk1.8 HashMap加入了红黑树
2.Hashtable 是不允许键或值为 null 的，HashMap 的键值则都可以为 null。
3.添加key-value的hash值算法不同：HashMap添加元素时，是使用自定义的哈希算法,而HashTable是直接采用key的hashCode()
4.同步性不同: Hashtable是同步(synchronized)的，适用于多线程环境,
而hashmap不是同步的，适用于单线程环境。多个线程可以共享一个Hashtable；而如果没有正确的同步的话，多个线程是不能共享HashMap的。

TreeSet可排序,底层由红黑树实现
HashSet底层由HashMap实现(Value为null),不可排序




悲观锁适合写操作多的场景，先加锁可以保证写操作时数据正确。
乐观锁适合读操作多的场景，不加锁的特点能够使其读操作的性能大幅提升。

Synchronized：底层使用指令码方式来控制锁的，映射成字节码指令就是增加来两个指令：monitorenter和monitorexit。当线程执行遇到monitorenter指令时会尝试获取内置锁，如果获取锁则锁计数器+1，如果没有获取锁则阻塞；当遇到monitorexit指令时锁计数器-1，如果计数器为0则释放锁。
Lock：底层是CAS乐观锁，依赖AbstractQueuedSynchronizer类，把所有的请求线程构成一个CLH队列。而对该队列的操作均通过Lock-Free（CAS）操作。
synchronized原始采用的是CPU悲观锁机制，即线程获得的是独占锁。 独占锁意味着其他线程只能依靠阻塞来等待线程释放锁。而在CPU转换线程阻塞时会引起线程上下文切换，当有很多线程竞争锁的时候，会引起CPU频繁的上下文切换导致效率很低。
而Lock用的是乐观锁方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。乐观锁实现的机制就是CAS操作（Compare and Swap）。

区别:
Synchronized是关键字，内置语言实现，Lock是接口。
Synchronized在线程发生异常时会自动释放锁，因此不会发生异常死锁。Lock异常时不会自动释放锁，所以需要在finally中实现释放锁。
Lock是可以中断锁，Synchronized是非中断锁，必须等待线程执行完成释放锁。
Lock可以使用读锁提高多线程读效率。

Java中“Reader-Writer”锁和“ReentrantReadWriteLock”之间的区别吗？哪个使用起来更灵活？
读写锁：
读写锁允许多个线程同时读取共享资源，但一次只有一个线程可以写入。当一个线程想要写入资源时，它必须等待所有读取者完成读取才能获取锁。
读写锁是不可重入的，这意味着持有读锁的线程在不释放读锁的情况下无法获取写锁。类似地，持有写锁的线程在不释放写锁的情况下无法获取读锁。
可重入读写锁：
ReentrantReadWriteLock 是读写锁的更灵活的实现。它允许多个线程同时获取读锁，也允许持有读锁的线程无需先释放读锁即可获取写锁。这使得线程可以将读锁升级为写锁。
另外，ReentrantReadWriteLock是可重入的，这意味着持有锁进行读或写的线程可以再次获取锁，而无需先释放锁。
总的来说，可重入读写锁比读写锁提供了更多的灵活性，但它也更复杂，如果使用不当，可能会导致死锁。当需要对锁进行更细粒度的控制时，通常建议使用 ReentrantReadWriteLock，而当需要简单性时，建议使用 Reader-Writer 锁。

所以关于要不要把 lock.lock() 写到 try 语句块里，文章的结论是：
1. 最好是把 lock.lock() 加锁方法写到 try 外面，这是一种规范，而不是强制。
2. 如果你非要写到 try 里面，那么 请写到 try 语句块的第一行，或者 lock 加锁方法前面不会存在可能出现异常的代码。
3. 最后，如果你代码中加锁放到了 try 语句里，麻烦参考第 1 点。

spring解决循环依赖问题:
三级缓存
第一级存放完全初始化好的Bean,可以直接使用
第二级存放原始的Bean,已经实例化但还没有进行赋值或依赖注入
第三级存放Bean工厂对象,生成原始Bean对象放入二级缓存中
核心思想:把Bean的实例化和Bean依赖注入进行分离



 Spring Boot核心注解
@SpringBootApplication
通常用在启动类上，申明让spring boot自动给程序进行必要的配置，它也是 Spring Boot 的核心注解，主要组合包含了以下 3 个注解：
@SpringBootConfiguration
组合了 @Configuration 注解，实现配置文件的功能。
@EnableAutoConfiguration
打开自动配置的功能，也可以关闭某个自动配置的选项。
如关闭数据源自动配置功能： @SpringBootApplication(exclude = { DataSourceAutoConfiguration.class })；
@ComponentScan
Spring组件扫描功能，让spring Boot扫描到Configuration类并把它加入到程序上下文。

Redis

主从:
父子节点命令:slave of A (IP A) (port A)
数据同步原理:
1.全量同步流程:
slave节点总是先请求增量同步
master节点判断replid,发现不一致,拒绝增量同步
master生成完整RDB,发送到slave
slave清空本地数据,加载RDB
master在RDB期间的命令记录在baklog中,持续将log中命令发给slave
slave执行接收到的命令,保持与master之间的同步

2.如果slave重启后同步,则执行增量同步(slave提交自己的offset,master获取repl_baklog中从offset之后的命令给slave)
baklog大小有上限,slave断开过久导致数据被覆盖则无法增量同步

优化主从集群:
master中启用无磁盘复制,避免磁盘IO
单节点内存占用不要太大,减少过多的IO
适当提高repl_baklog大小
限制master上的slave节点数量,可以采用主-从-从链式结构

哨兵:
哨兵机制来实现主从集群的自动故障恢复,作业包括监控,自动故障恢复,通知客户端

监控:每隔一秒向集群的每个实例发送ping命令,若某实例在规定时间未响应,则认为其主观下线;若超过指定数量的哨兵认为下线,则实例客观下线

故障转移步骤:
1)首先选举新master:首先判断slave节点与master节点断开时间,超过指定值排除;然后判断优先级的值,越小优先级越高;优先级一样判断offset值,越大说明数据越新;最后判断运行id大小,越小优先级越高
2)其他节点都slave of 新master
3)故障节点slave of 新master


缓存问题
大量缓存数据在同一时间过期（失效）或者 Redis 故障宕机时，如果此时有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃，这就是缓存雪崩
针对大量数据同时过期而引发的缓存雪崩问题,常见的应对方法有下面这几种：
均匀设置过期时间；
互斥锁；
后台更新缓存；

针对 Redis 故障宕机而引发的缓存雪崩问题，常见的应对方法有下面这几种：
服务熔断或请求限流机制；
构建 Redis 缓存高可靠集群;

缓存击穿跟缓存雪崩很相似，你可以认为缓存击穿是缓存雪崩的一个子集。
应对缓存击穿可以采取前面说到两种方案：
互斥锁方案，保证同一时间只有一个业务线程更新缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。
不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间;

当用户访问的数据，既不在缓存中，也不在数据库中，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是缓存穿透的问题。

缓存穿透的发生一般有这两种情况：
业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据；
黑客恶意攻击，故意大量访问某些读取不存在数据的业务；

应对缓存穿透的方案，常见的方案有三种。
第一种方案，非法请求的限制；
第二种方案，缓存空值或者默认值；
第三种方案，使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在；



